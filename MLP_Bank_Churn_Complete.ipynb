{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ====== 1. Generate Dataset ======\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "data = {\n",
    "    'age': np.random.randint(18, 80, n_samples),\n",
    "    'credit_score': np.random.normal(650, 100, n_samples).astype(int),\n",
    "    'balance': np.round(np.random.exponential(50000, n_samples), 2),\n",
    "    'products_number': np.random.randint(1, 5, n_samples),\n",
    "    'estimated_salary': np.round(np.random.uniform(20000, 150000, n_samples), 2),\n",
    "    'country': np.random.choice(['Germany', 'France', 'Spain'], n_samples),\n",
    "    'gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "    'tenure': np.random.randint(0, 10, n_samples),\n",
    "    'has_credit_card': np.random.choice([0, 1], n_samples),\n",
    "    'is_active_member': np.random.choice([0, 1], n_samples)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create target variable\n",
    "df['churn'] = (\n",
    "    (df['balance'] > 80000) | \n",
    "    (df['credit_score'] < 550) |\n",
    "    (df['products_number'] == 1) |\n",
    "    ((df['age'] > 65) & (df['is_active_member'] == 0))\n",
    ").astype(int)\n",
    "\n",
    "print(f\"Dataset: {len(df)} rows Ã— {len(df.columns)} columns\")\n",
    "print(f\"Churn rate: {df['churn'].mean():.2%}\\n\")\n",
    "\n",
    "# ====== 2. Data Preprocessing ======\n",
    "# Encode categorical variables\n",
    "le_country = LabelEncoder()\n",
    "le_gender = LabelEncoder()\n",
    "df['country'] = le_country.fit_transform(df['country'])\n",
    "df['gender'] = le_gender.fit_transform(df['gender'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('churn', axis=1).values\n",
    "y = df['churn'].values.reshape(-1, 1)\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\\n\")\n",
    "\n",
    "# ====== 3. Build 3-Layer MLP with NumPy ======\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Xavier initialization for better convergence\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0/input_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0/hidden_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Calculate gradient for output layer\n",
    "        dz2 = output - y\n",
    "        dW2 = np.dot(self.a1.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Calculate gradient for hidden layer\n",
    "        dz1 = np.dot(dz2, self.W2.T) * self.sigmoid_derivative(self.a1)\n",
    "        dW1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        loss = -np.mean(y_true * np.log(y_pred + 1e-8) + (1 - y_true) * np.log(1 - y_pred + 1e-8))\n",
    "        return loss\n",
    "    \n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output, learning_rate)\n",
    "            loss = self.compute_loss(y, output)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if (epoch + 1) % 200 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return (output > 0.5).astype(int)\n",
    "\n",
    "# ====== 4. Train Model ======\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "mlp = MLP(input_size, hidden_size, output_size)\n",
    "print(\"Training MLP with improved settings...\\n\")\n",
    "losses = mlp.train(X_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "# ====== 5. Evaluation ======\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "y_pred_test = mlp.predict(X_test)\n",
    "\n",
    "train_accuracy = np.mean(y_pred_train == y_train)\n",
    "test_accuracy = np.mean(y_pred_test == y_test)\n",
    "\n",
    "print(f\"\\nâœ“ Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"âœ“ Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====== Question 3: Compare Activation Functions ======\n",
    "\n",
    "class MLP_MultiActivation:\n",
    "    def __init__(self, input_size, hidden_size, output_size, activation='sigmoid'):\n",
    "        self.activation_type = activation\n",
    "        \n",
    "        # Xavier initialization\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0/input_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0/hidden_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    def relu(self, z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def relu_derivative(self, z):\n",
    "        return (z > 0).astype(float)\n",
    "    \n",
    "    def tanh(self, z):\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    def tanh_derivative(self, z):\n",
    "        return 1 - z**2\n",
    "    \n",
    "    def activate(self, z):\n",
    "        if self.activation_type == 'sigmoid':\n",
    "            return self.sigmoid(z)\n",
    "        elif self.activation_type == 'relu':\n",
    "            return self.relu(z)\n",
    "        elif self.activation_type == 'tanh':\n",
    "            return self.tanh(z)\n",
    "    \n",
    "    def activate_derivative(self, z):\n",
    "        if self.activation_type == 'sigmoid':\n",
    "            return self.sigmoid_derivative(z)\n",
    "        elif self.activation_type == 'relu':\n",
    "            return self.relu_derivative(z)\n",
    "        elif self.activation_type == 'tanh':\n",
    "            return self.tanh_derivative(z)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.activate(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)  # Output layer always sigmoid for binary classification\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Output layer gradient\n",
    "        dz2 = output - y\n",
    "        dW2 = np.dot(self.a1.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Hidden layer gradient\n",
    "        dz1 = np.dot(dz2, self.W2.T) * self.activate_derivative(self.a1)\n",
    "        dW1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Update weights\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        loss = -np.mean(y_true * np.log(y_pred + 1e-8) + (1 - y_true) * np.log(1 - y_pred + 1e-8))\n",
    "        return loss\n",
    "    \n",
    "    def train(self, X, y, epochs, learning_rate, verbose=False):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output, learning_rate)\n",
    "            loss = self.compute_loss(y, output)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 200 == 0:\n",
    "                print(f\"  Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return (output > 0.5).astype(int)\n",
    "\n",
    "# Train and compare different activation functions\n",
    "activations = ['sigmoid', 'relu', 'tanh']\n",
    "results = {}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Comparing Activation Functions: Sigmoid vs ReLU vs Tanh\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for activation in activations:\n",
    "    print(f\"\\n--- Training with {activation.upper()} activation ---\")\n",
    "    \n",
    "    model = MLP_MultiActivation(input_size, hidden_size, output_size, activation=activation)\n",
    "    losses = model.train(X_train, y_train, epochs=1000, learning_rate=0.1, verbose=True)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    train_acc = np.mean(y_pred_train == y_train)\n",
    "    test_acc = np.mean(y_pred_test == y_test)\n",
    "    \n",
    "    results[activation] = {\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'final_loss': losses[-1],\n",
    "        'losses': losses\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"âœ“ Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Activation':<12} {'Train Acc':<12} {'Test Acc':<12} {'Final Loss':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for activation in activations:\n",
    "    r = results[activation]\n",
    "    print(f\"{activation.upper():<12} {r['train_accuracy']:<12.4f} {r['test_accuracy']:<12.4f} {r['final_loss']:<12.4f}\")\n",
    "\n",
    "# Find best activation\n",
    "best_activation = max(results.items(), key=lambda x: x[1]['test_accuracy'])\n",
    "print(f\"\\nðŸ† Best Activation: {best_activation[0].upper()} with Test Accuracy = {best_activation[1]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====== Question 4: Experiment with Learning Rates ======\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test different learning rates\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "lr_results = {}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Experimenting with Different Learning Rates\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n--- Training with Learning Rate = {lr} ---\")\n",
    "    \n",
    "    model = MLP(input_size, hidden_size, output_size)\n",
    "    losses = model.train(X_train, y_train, epochs=1000, learning_rate=lr)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    train_acc = np.mean(y_pred_train == y_train)\n",
    "    test_acc = np.mean(y_pred_test == y_test)\n",
    "    \n",
    "    lr_results[lr] = {\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'losses': losses\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"âœ“ Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"âœ“ Final Loss: {losses[-1]:.4f}\")\n",
    "\n",
    "# Visualize loss curves\n",
    "print(\"\\n--- Visualizing Convergence Speed ---\")\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Loss curves\n",
    "plt.subplot(1, 2, 1)\n",
    "for lr in learning_rates:\n",
    "    plt.plot(lr_results[lr]['losses'], label=f'LR = {lr}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves for Different Learning Rates')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "lrs = [str(lr) for lr in learning_rates]\n",
    "train_accs = [lr_results[lr]['train_accuracy'] for lr in learning_rates]\n",
    "test_accs = [lr_results[lr]['test_accuracy'] for lr in learning_rates]\n",
    "\n",
    "x = np.arange(len(lrs))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_accs, width, label='Train Accuracy', alpha=0.8)\n",
    "plt.bar(x + width/2, test_accs, width, label='Test Accuracy', alpha=0.8)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xticks(x, lrs)\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LEARNING RATE COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'LR':<10} {'Train Acc':<12} {'Test Acc':<12} {'Final Loss':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for lr in learning_rates:\n",
    "    r = lr_results[lr]\n",
    "    print(f\"{lr:<10} {r['train_accuracy']:<12.4f} {r['test_accuracy']:<12.4f} {r['losses'][-1]:<12.4f}\")\n",
    "\n",
    "# Find best learning rate\n",
    "best_lr = max(lr_results.items(), key=lambda x: x[1]['test_accuracy'])\n",
    "print(f\"\\nðŸ† Best Learning Rate: {best_lr[0]} with Test Accuracy = {best_lr[1]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====== Question 5: Analyze Hidden Layer Size Impact ======\n",
    "\n",
    "# Test different hidden layer sizes\n",
    "hidden_sizes = [16, 64, 128]\n",
    "hidden_results = {}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Analyzing Hidden Layer Size Impact\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for h_size in hidden_sizes:\n",
    "    print(f\"\\n--- Training with Hidden Size = {h_size} neurons ---\")\n",
    "    \n",
    "    model = MLP(input_size, h_size, output_size)\n",
    "    losses = model.train(X_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    train_acc = np.mean(y_pred_train == y_train)\n",
    "    test_acc = np.mean(y_pred_test == y_test)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = (input_size * h_size + h_size) + (h_size * output_size + output_size)\n",
    "    \n",
    "    hidden_results[h_size] = {\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'losses': losses,\n",
    "        'parameters': total_params\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"âœ“ Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"âœ“ Total Parameters: {total_params}\")\n",
    "\n",
    "# Visualize results\n",
    "print(\"\\n--- Visualizing Hidden Layer Impact ---\")\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss curves\n",
    "plt.subplot(1, 3, 1)\n",
    "for h_size in hidden_sizes:\n",
    "    plt.plot(hidden_results[h_size]['losses'], label=f'{h_size} neurons')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves for Different Hidden Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy comparison\n",
    "plt.subplot(1, 3, 2)\n",
    "sizes = [str(h) for h in hidden_sizes]\n",
    "train_accs = [hidden_results[h]['train_accuracy'] for h in hidden_sizes]\n",
    "test_accs = [hidden_results[h]['test_accuracy'] for h in hidden_sizes]\n",
    "\n",
    "x = np.arange(len(sizes))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_accs, width, label='Train Accuracy', alpha=0.8)\n",
    "plt.bar(x + width/2, test_accs, width, label='Test Accuracy', alpha=0.8)\n",
    "plt.xlabel('Hidden Layer Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xticks(x, sizes)\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Parameters vs Accuracy\n",
    "plt.subplot(1, 3, 3)\n",
    "params = [hidden_results[h]['parameters'] for h in hidden_sizes]\n",
    "test_accs = [hidden_results[h]['test_accuracy'] for h in hidden_sizes]\n",
    "\n",
    "plt.plot(params, test_accs, marker='o', linewidth=2, markersize=10)\n",
    "for i, h in enumerate(hidden_sizes):\n",
    "    plt.annotate(f'{h} neurons', (params[i], test_accs[i]), \n",
    "                textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "plt.xlabel('Number of Parameters')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Model Complexity vs Performance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"HIDDEN LAYER SIZE COMPARISON SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Hidden Size':<15} {'Parameters':<15} {'Train Acc':<12} {'Test Acc':<12}\")\n",
    "print(\"-\" * 70)\n",
    "for h_size in hidden_sizes:\n",
    "    r = hidden_results[h_size]\n",
    "    print(f\"{h_size:<15} {r['parameters']:<15} {r['train_accuracy']:<12.4f} {r['test_accuracy']:<12.4f}\")\n",
    "\n",
    "# Find best hidden size\n",
    "best_hidden = max(hidden_results.items(), key=lambda x: x[1]['test_accuracy'])\n",
    "print(f\"\\nðŸ† Best Hidden Size: {best_hidden[0]} neurons with Test Accuracy = {best_hidden[1]['test_accuracy']:.4f}\")\n",
    "\n",
    "# Analysis\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "overfitting_gap = []\n",
    "for h_size in hidden_sizes:\n",
    "    gap = hidden_results[h_size]['train_accuracy'] - hidden_results[h_size]['test_accuracy']\n",
    "    overfitting_gap.append(gap)\n",
    "    status = \"Possible Overfitting\" if gap > 0.05 else \"Good Generalization\"\n",
    "    print(f\"Hidden Size {h_size}: Train-Test Gap = {gap:.4f} â†’ {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====== Question 6: Add Regularization Techniques (L2 & Dropout) ======\n",
    "\n",
    "class MLP_Regularized:\n",
    "    def __init__(self, input_size, hidden_size, output_size, l2_lambda=0.0, dropout_rate=0.0):\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Xavier initialization\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0/input_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0/hidden_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    def dropout(self, X, training=True):\n",
    "        if training and self.dropout_rate > 0:\n",
    "            mask = np.random.binomial(1, 1-self.dropout_rate, size=X.shape) / (1-self.dropout_rate)\n",
    "            return X * mask, mask\n",
    "        return X, None\n",
    "    \n",
    "    def forward(self, X, training=True):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        \n",
    "        # Apply dropout to hidden layer\n",
    "        self.a1_dropout, self.dropout_mask = self.dropout(self.a1, training)\n",
    "        \n",
    "        self.z2 = np.dot(self.a1_dropout, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Output layer gradient\n",
    "        dz2 = output - y\n",
    "        dW2 = np.dot(self.a1_dropout.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Add L2 regularization to weights\n",
    "        if self.l2_lambda > 0:\n",
    "            dW2 += (self.l2_lambda / m) * self.W2\n",
    "        \n",
    "        # Hidden layer gradient\n",
    "        dz1 = np.dot(dz2, self.W2.T) * self.sigmoid_derivative(self.a1_dropout)\n",
    "        \n",
    "        # Apply dropout mask during backprop\n",
    "        if self.dropout_mask is not None:\n",
    "            dz1 = dz1 * self.dropout_mask\n",
    "        \n",
    "        dW1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Add L2 regularization to weights\n",
    "        if self.l2_lambda > 0:\n",
    "            dW1 += (self.l2_lambda / m) * self.W1\n",
    "        \n",
    "        # Update weights\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        cross_entropy_loss = -np.mean(y_true * np.log(y_pred + 1e-8) + (1 - y_true) * np.log(1 - y_pred + 1e-8))\n",
    "        \n",
    "        # Add L2 regularization term to loss\n",
    "        if self.l2_lambda > 0:\n",
    "            l2_loss = (self.l2_lambda / (2 * m)) * (np.sum(self.W1**2) + np.sum(self.W2**2))\n",
    "            return cross_entropy_loss + l2_loss\n",
    "        \n",
    "        return cross_entropy_loss\n",
    "    \n",
    "    def train(self, X, y, epochs, learning_rate, verbose=False):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X, training=True)\n",
    "            self.backward(X, y, output, learning_rate)\n",
    "            loss = self.compute_loss(y, output)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            if verbose and (epoch + 1) % 200 == 0:\n",
    "                print(f\"  Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X, training=False)\n",
    "        return (output > 0.5).astype(int)\n",
    "\n",
    "# Test different regularization techniques\n",
    "configs = [\n",
    "    {'name': 'No Regularization', 'l2': 0.0, 'dropout': 0.0},\n",
    "    {'name': 'L2 Only (Î»=0.01)', 'l2': 0.01, 'dropout': 0.0},\n",
    "    {'name': 'Dropout Only (p=0.2)', 'l2': 0.0, 'dropout': 0.2},\n",
    "    {'name': 'L2 + Dropout', 'l2': 0.01, 'dropout': 0.2}\n",
    "]\n",
    "\n",
    "reg_results = {}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Regularization Techniques\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\n--- {config['name']} ---\")\n",
    "    \n",
    "    model = MLP_Regularized(input_size, hidden_size, output_size, \n",
    "                           l2_lambda=config['l2'], dropout_rate=config['dropout'])\n",
    "    losses = model.train(X_train, y_train, epochs=1000, learning_rate=0.1, verbose=True)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    train_acc = np.mean(y_pred_train == y_train)\n",
    "    test_acc = np.mean(y_pred_test == y_test)\n",
    "    \n",
    "    reg_results[config['name']] = {\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'losses': losses,\n",
    "        'overfitting_gap': train_acc - test_acc\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"âœ“ Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"âœ“ Overfitting Gap: {train_acc - test_acc:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "print(\"\\n--- Visualizing Regularization Impact ---\")\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss curves\n",
    "plt.subplot(1, 3, 1)\n",
    "for name in reg_results.keys():\n",
    "    plt.plot(reg_results[name]['losses'], label=name)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves with Different Regularization')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy comparison\n",
    "plt.subplot(1, 3, 2)\n",
    "names = list(reg_results.keys())\n",
    "train_accs = [reg_results[n]['train_accuracy'] for n in names]\n",
    "test_accs = [reg_results[n]['test_accuracy'] for n in names]\n",
    "\n",
    "x = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_accs, width, label='Train Accuracy', alpha=0.8)\n",
    "plt.bar(x + width/2, test_accs, width, label='Test Accuracy', alpha=0.8)\n",
    "plt.xlabel('Regularization Method')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xticks(x, names, rotation=15, ha='right')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Overfitting gap\n",
    "plt.subplot(1, 3, 3)\n",
    "gaps = [reg_results[n]['overfitting_gap'] for n in names]\n",
    "colors = ['red' if g > 0.05 else 'green' for g in gaps]\n",
    "\n",
    "plt.bar(names, gaps, color=colors, alpha=0.7)\n",
    "plt.xlabel('Regularization Method')\n",
    "plt.ylabel('Train-Test Gap')\n",
    "plt.title('Overfitting Analysis')\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.axhline(y=0.05, color='orange', linestyle='--', label='Threshold (0.05)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REGULARIZATION COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Method':<25} {'Train Acc':<12} {'Test Acc':<12} {'Gap':<12}\")\n",
    "print(\"-\" * 80)\n",
    "for name in reg_results.keys():\n",
    "    r = reg_results[name]\n",
    "    print(f\"{name:<25} {r['train_accuracy']:<12.4f} {r['test_accuracy']:<12.4f} {r['overfitting_gap']:<12.4f}\")\n",
    "\n",
    "# Find best method\n",
    "best_method = min(reg_results.items(), key=lambda x: x[1]['overfitting_gap'])\n",
    "print(f\"\\nðŸ† Best Method (lowest overfitting): {best_method[0]} with Gap = {best_method[1]['overfitting_gap']:.4f}\")\n",
    "\n",
    "best_test_acc = max(reg_results.items(), key=lambda x: x[1]['test_accuracy'])\n",
    "print(f\"ðŸŽ¯ Best Test Accuracy: {best_test_acc[0]} with Accuracy = {best_test_acc[1]['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====== Question 7: Comprehensive Evaluation Metrics ======\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive evaluation metrics\n",
    "    \"\"\"\n",
    "    # Confusion Matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    \n",
    "    # Recall (Sensitivity)\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # F1 Score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Specificity\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # ROC-AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'specificity': specificity,\n",
    "        'roc_auc': roc_auc,\n",
    "        'confusion_matrix': (tn, fp, fn, tp),\n",
    "        'roc_curve': (fpr, tpr)\n",
    "    }\n",
    "\n",
    "# Train a model for evaluation\n",
    "print(\"=\" * 60)\n",
    "print(\"Comprehensive Evaluation Metrics\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- Training Model ---\")\n",
    "model = MLP_Regularized(input_size, hidden_size, output_size, l2_lambda=0.01, dropout_rate=0.2)\n",
    "losses = model.train(X_train, y_train, epochs=1000, learning_rate=0.1, verbose=True)\n",
    "\n",
    "# Get predictions and probabilities\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "y_pred_proba_train = model.forward(X_train, training=False)\n",
    "y_pred_proba_test = model.forward(X_test, training=False)\n",
    "\n",
    "# Calculate metrics for train and test sets\n",
    "train_metrics = calculate_metrics(y_train, y_pred_train, y_pred_proba_train)\n",
    "test_metrics = calculate_metrics(y_test, y_pred_test, y_pred_proba_test)\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAIN SET METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:    {train_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision:   {train_metrics['precision']:.4f}\")\n",
    "print(f\"Recall:      {train_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score:    {train_metrics['f1_score']:.4f}\")\n",
    "print(f\"Specificity: {train_metrics['specificity']:.4f}\")\n",
    "print(f\"ROC-AUC:     {train_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST SET METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy:    {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision:   {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall:      {test_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score:    {test_metrics['f1_score']:.4f}\")\n",
    "print(f\"Specificity: {test_metrics['specificity']:.4f}\")\n",
    "print(f\"ROC-AUC:     {test_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Visualize metrics\n",
    "print(\"\\n--- Visualizing Evaluation Metrics ---\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Confusion Matrix - Train\n",
    "plt.subplot(2, 3, 1)\n",
    "tn, fp, fn, tp = train_metrics['confusion_matrix']\n",
    "cm_train = np.array([[tn, fp], [fn, tp]])\n",
    "plt.imshow(cm_train, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Train')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['No Churn', 'Churn'])\n",
    "plt.yticks(tick_marks, ['No Churn', 'Churn'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm_train[i, j], ha=\"center\", va=\"center\", color=\"red\", fontsize=16)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Plot 2: Confusion Matrix - Test\n",
    "plt.subplot(2, 3, 2)\n",
    "tn, fp, fn, tp = test_metrics['confusion_matrix']\n",
    "cm_test = np.array([[tn, fp], [fn, tp]])\n",
    "plt.imshow(cm_test, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test')\n",
    "plt.colorbar()\n",
    "plt.xticks(tick_marks, ['No Churn', 'Churn'])\n",
    "plt.yticks(tick_marks, ['No Churn', 'Churn'])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm_test[i, j], ha=\"center\", va=\"center\", color=\"red\", fontsize=16)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Plot 3: Metrics Comparison\n",
    "plt.subplot(2, 3, 3)\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity']\n",
    "train_values = [train_metrics['accuracy'], train_metrics['precision'], \n",
    "                train_metrics['recall'], train_metrics['f1_score'], train_metrics['specificity']]\n",
    "test_values = [test_metrics['accuracy'], test_metrics['precision'], \n",
    "               test_metrics['recall'], test_metrics['f1_score'], test_metrics['specificity']]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_values, width, label='Train', alpha=0.8)\n",
    "plt.bar(x + width/2, test_values, width, label='Test', alpha=0.8)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance Metrics Comparison')\n",
    "plt.xticks(x, metrics_names, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: ROC Curve - Train\n",
    "plt.subplot(2, 3, 4)\n",
    "fpr_train, tpr_train = train_metrics['roc_curve']\n",
    "plt.plot(fpr_train, tpr_train, color='blue', lw=2, \n",
    "         label=f'ROC Curve (AUC = {train_metrics[\"roc_auc\"]:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Train Set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: ROC Curve - Test\n",
    "plt.subplot(2, 3, 5)\n",
    "fpr_test, tpr_test = test_metrics['roc_curve']\n",
    "plt.plot(fpr_test, tpr_test, color='green', lw=2, \n",
    "         label=f'ROC Curve (AUC = {test_metrics[\"roc_auc\"]:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Test Set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Metrics Radar Chart\n",
    "plt.subplot(2, 3, 6, projection='polar')\n",
    "categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity']\n",
    "values_test = [test_metrics['accuracy'], test_metrics['precision'], \n",
    "               test_metrics['recall'], test_metrics['f1_score'], test_metrics['specificity']]\n",
    "values_test += values_test[:1]  # Complete the circle\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(angles, values_test, 'o-', linewidth=2, label='Test Set')\n",
    "ax.fill(angles, values_test, alpha=0.25)\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Performance Radar Chart', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"âœ“ The model achieves {test_metrics['f1_score']:.2%} F1-Score on test set\")\n",
    "print(f\"âœ“ ROC-AUC of {test_metrics['roc_auc']:.4f} indicates {'excellent' if test_metrics['roc_auc'] > 0.9 else 'good' if test_metrics['roc_auc'] > 0.8 else 'fair'} discrimination\")\n",
    "print(f\"âœ“ Recall: {test_metrics['recall']:.2%} (ability to find churned customers)\")\n",
    "print(f\"âœ“ Precision: {test_metrics['precision']:.2%} (accuracy of churn predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====== Question 8: Visualize Training Progress ======\n",
    "\n",
    "class MLP_WithValidation:\n",
    "    def __init__(self, input_size, hidden_size, output_size, l2_lambda=0.0, dropout_rate=0.0):\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Xavier initialization\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0/input_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0/hidden_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    def dropout(self, X, training=True):\n",
    "        if training and self.dropout_rate > 0:\n",
    "            mask = np.random.binomial(1, 1-self.dropout_rate, size=X.shape) / (1-self.dropout_rate)\n",
    "            return X * mask, mask\n",
    "        return X, None\n",
    "    \n",
    "    def forward(self, X, training=True):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        \n",
    "        self.a1_dropout, self.dropout_mask = self.dropout(self.a1, training)\n",
    "        \n",
    "        self.z2 = np.dot(self.a1_dropout, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        dz2 = output - y\n",
    "        dW2 = np.dot(self.a1_dropout.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        if self.l2_lambda > 0:\n",
    "            dW2 += (self.l2_lambda / m) * self.W2\n",
    "        \n",
    "        dz1 = np.dot(dz2, self.W2.T) * self.sigmoid_derivative(self.a1_dropout)\n",
    "        \n",
    "        if self.dropout_mask is not None:\n",
    "            dz1 = dz1 * self.dropout_mask\n",
    "        \n",
    "        dW1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        if self.l2_lambda > 0:\n",
    "            dW1 += (self.l2_lambda / m) * self.W1\n",
    "        \n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        cross_entropy_loss = -np.mean(y_true * np.log(y_pred + 1e-8) + (1 - y_true) * np.log(1 - y_pred + 1e-8))\n",
    "        \n",
    "        if self.l2_lambda > 0:\n",
    "            l2_loss = (self.l2_lambda / (2 * m)) * (np.sum(self.W1**2) + np.sum(self.W2**2))\n",
    "            return cross_entropy_loss + l2_loss\n",
    "        \n",
    "        return cross_entropy_loss\n",
    "    \n",
    "    def compute_accuracy(self, y_true, y_pred):\n",
    "        predictions = (y_pred > 0.5).astype(int)\n",
    "        return np.mean(predictions == y_true)\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, learning_rate):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            output_train = self.forward(X_train, training=True)\n",
    "            self.backward(X_train, y_train, output_train, learning_rate)\n",
    "            train_loss = self.compute_loss(y_train, output_train)\n",
    "            train_acc = self.compute_accuracy(y_train, output_train)\n",
    "            \n",
    "            # Validation phase (no dropout)\n",
    "            output_val = self.forward(X_val, training=False)\n",
    "            val_loss = self.compute_loss(y_val, output_val)\n",
    "            val_acc = self.compute_accuracy(y_val, output_val)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            train_accuracies.append(train_acc)\n",
    "            val_accuracies.append(val_acc)\n",
    "            \n",
    "            if (epoch + 1) % 200 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "                print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "                print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_accuracies': val_accuracies\n",
    "        }\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X, training=False)\n",
    "        return (output > 0.5).astype(int)\n",
    "\n",
    "# Split train data into train and validation\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Training Progress Visualization\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train set: {X_train_split.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val_split.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\\n\")\n",
    "\n",
    "# Train model with validation tracking\n",
    "print(\"--- Training Model ---\")\n",
    "model = MLP_WithValidation(input_size, hidden_size, output_size, l2_lambda=0.01, dropout_rate=0.2)\n",
    "history = model.train(X_train_split, y_train_split, X_val_split, y_val_split, \n",
    "                     epochs=1000, learning_rate=0.1)\n",
    "\n",
    "# Final evaluation on test set\n",
    "y_pred_test = model.predict(X_test)\n",
    "test_accuracy = np.mean(y_pred_test == y_test)\n",
    "print(f\"\\nâœ“ Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Visualize training progress\n",
    "print(\"\\n--- Visualizing Training Progress ---\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Loss curves\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(history['train_losses'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history['val_losses'], label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy curves\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(history['train_accuracies'], label='Train Accuracy', linewidth=2)\n",
    "plt.plot(history['val_accuracies'], label='Validation Accuracy', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Loss difference (overfitting indicator)\n",
    "plt.subplot(2, 3, 3)\n",
    "loss_diff = np.array(history['val_losses']) - np.array(history['train_losses'])\n",
    "plt.plot(loss_diff, color='red', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss - Train Loss')\n",
    "plt.title('Overfitting Indicator (Loss Gap)')\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Smoothed loss curves\n",
    "plt.subplot(2, 3, 4)\n",
    "window = 50\n",
    "if len(history['train_losses']) >= window:\n",
    "    train_loss_smooth = np.convolve(history['train_losses'], np.ones(window)/window, mode='valid')\n",
    "    val_loss_smooth = np.convolve(history['val_losses'], np.ones(window)/window, mode='valid')\n",
    "    plt.plot(train_loss_smooth, label='Train Loss (Smoothed)', linewidth=2)\n",
    "    plt.plot(val_loss_smooth, label='Val Loss (Smoothed)', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Smoothed Loss Curves (Window={window})')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Accuracy difference\n",
    "plt.subplot(2, 3, 5)\n",
    "acc_diff = np.array(history['train_accuracies']) - np.array(history['val_accuracies'])\n",
    "plt.plot(acc_diff, color='orange', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Acc - Val Acc')\n",
    "plt.title('Generalization Gap (Accuracy)')\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "plt.axhline(y=0.05, color='red', linestyle='--', alpha=0.3, label='Warning Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Learning rate schedule (if needed)\n",
    "plt.subplot(2, 3, 6)\n",
    "epochs_range = np.arange(len(history['train_losses']))\n",
    "final_train_loss = history['train_losses'][-1]\n",
    "final_val_loss = history['val_losses'][-1]\n",
    "final_train_acc = history['train_accuracies'][-1]\n",
    "final_val_acc = history['val_accuracies'][-1]\n",
    "\n",
    "stats_text = f\"\"\"\n",
    "Final Statistics:\n",
    "\n",
    "Train Loss: {final_train_loss:.4f}\n",
    "Val Loss: {final_val_loss:.4f}\n",
    "\n",
    "Train Acc: {final_train_acc:.4f}\n",
    "Val Acc: {final_val_acc:.4f}\n",
    "\n",
    "Test Acc: {test_accuracy:.4f}\n",
    "\n",
    "Loss Gap: {final_val_loss - final_train_loss:.4f}\n",
    "Acc Gap: {final_train_acc - final_val_acc:.4f}\n",
    "\"\"\"\n",
    "\n",
    "plt.text(0.5, 0.5, stats_text, transform=plt.gca().transAxes,\n",
    "         fontsize=12, verticalalignment='center', horizontalalignment='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "         family='monospace')\n",
    "plt.axis('off')\n",
    "plt.title('Training Summary Statistics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING PROGRESS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for overfitting\n",
    "final_loss_gap = history['val_losses'][-1] - history['train_losses'][-1]\n",
    "final_acc_gap = history['train_accuracies'][-1] - history['val_accuracies'][-1]\n",
    "\n",
    "print(f\"Final Training Loss: {history['train_losses'][-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {history['val_losses'][-1]:.4f}\")\n",
    "print(f\"Loss Gap: {final_loss_gap:.4f}\")\n",
    "\n",
    "print(f\"\\nFinal Training Accuracy: {history['train_accuracies'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history['val_accuracies'][-1]:.4f}\")\n",
    "print(f\"Accuracy Gap: {final_acc_gap:.4f}\")\n",
    "\n",
    "# Convergence check\n",
    "if abs(history['train_losses'][-1] - history['train_losses'][-100]) < 0.001:\n",
    "    print(\"\\nâœ“ Model has converged\")\n",
    "else:\n",
    "    print(\"\\nâš  Model may benefit from more epochs\")\n",
    "\n",
    "# Overfitting check\n",
    "if final_acc_gap > 0.05:\n",
    "    print(\"âš  Warning: Possible overfitting detected!\")\n",
    "    print(\"  Consider: more regularization, more data, or early stopping\")\n",
    "else:\n",
    "    print(\"âœ“ Good generalization - no significant overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ====== Question 9: Feature Importance Analysis ======\n",
    "\n",
    "def permutation_importance(model, X, y, feature_names, n_repeats=10):\n",
    "    \"\"\"\n",
    "    Calculate feature importance using permutation method\n",
    "    \"\"\"\n",
    "    # Baseline accuracy\n",
    "    baseline_predictions = model.predict(X)\n",
    "    baseline_accuracy = np.mean(baseline_predictions == y)\n",
    "    \n",
    "    importances = []\n",
    "    \n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        print(f\"  Calculating importance for: {feature_name}\")\n",
    "        \n",
    "        feature_importances = []\n",
    "        for _ in range(n_repeats):\n",
    "            # Copy data and shuffle one feature\n",
    "            X_permuted = X.copy()\n",
    "            X_permuted[:, i] = np.random.permutation(X_permuted[:, i])\n",
    "            \n",
    "            # Calculate accuracy with permuted feature\n",
    "            permuted_predictions = model.predict(X_permuted)\n",
    "            permuted_accuracy = np.mean(permuted_predictions == y)\n",
    "            \n",
    "            # Importance = drop in accuracy\n",
    "            importance = baseline_accuracy - permuted_accuracy\n",
    "            feature_importances.append(importance)\n",
    "        \n",
    "        # Average over repeats\n",
    "        importances.append(np.mean(feature_importances))\n",
    "    \n",
    "    return np.array(importances)\n",
    "\n",
    "def weight_based_importance(model, feature_names):\n",
    "    \"\"\"\n",
    "    Calculate feature importance based on weights of first layer\n",
    "    \"\"\"\n",
    "    # Sum of absolute weights connecting each input to hidden layer\n",
    "    importances = np.sum(np.abs(model.W1), axis=1)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    importances = importances / np.sum(importances)\n",
    "    \n",
    "    return importances\n",
    "\n",
    "# Feature names\n",
    "feature_names = ['age', 'credit_score', 'balance', 'products_number', \n",
    "                'estimated_salary', 'country', 'gender', 'tenure', \n",
    "                'has_credit_card', 'is_active_member']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Feature Importance Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use the previously trained model\n",
    "print(\"\\n--- Method 1: Permutation Importance ---\")\n",
    "print(\"Calculating permutation importance (this may take a moment)...\")\n",
    "perm_importance = permutation_importance(model, X_test, y_test, feature_names, n_repeats=10)\n",
    "\n",
    "print(\"\\n--- Method 2: Weight-Based Importance ---\")\n",
    "weight_importance = weight_based_importance(model, feature_names)\n",
    "\n",
    "# Combine results\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Permutation_Importance': perm_importance,\n",
    "    'Weight_Importance': weight_importance\n",
    "})\n",
    "\n",
    "# Sort by permutation importance\n",
    "importance_df = importance_df.sort_values('Permutation_Importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE IMPORTANCE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Visualize importance\n",
    "print(\"\\n--- Visualizing Feature Importance ---\")\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Permutation Importance (horizontal bar)\n",
    "plt.subplot(2, 3, 1)\n",
    "sorted_idx = np.argsort(perm_importance)\n",
    "plt.barh(np.array(feature_names)[sorted_idx], perm_importance[sorted_idx], color='steelblue')\n",
    "plt.xlabel('Importance (Accuracy Drop)')\n",
    "plt.title('Permutation Feature Importance')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 2: Weight-Based Importance (horizontal bar)\n",
    "plt.subplot(2, 3, 2)\n",
    "sorted_idx = np.argsort(weight_importance)\n",
    "plt.barh(np.array(feature_names)[sorted_idx], weight_importance[sorted_idx], color='coral')\n",
    "plt.xlabel('Normalized Weight')\n",
    "plt.title('Weight-Based Feature Importance')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 3: Comparison of both methods\n",
    "plt.subplot(2, 3, 3)\n",
    "x = np.arange(len(feature_names))\n",
    "width = 0.35\n",
    "\n",
    "# Normalize permutation importance for comparison\n",
    "perm_norm = perm_importance / np.max(perm_importance) if np.max(perm_importance) > 0 else perm_importance\n",
    "\n",
    "sorted_features = importance_df['Feature'].values\n",
    "sorted_perm = importance_df['Permutation_Importance'].values / np.max(importance_df['Permutation_Importance'].values)\n",
    "sorted_weight = importance_df['Weight_Importance'].values\n",
    "\n",
    "x_pos = np.arange(len(sorted_features))\n",
    "plt.barh(x_pos - width/2, sorted_perm, width, label='Permutation', alpha=0.8)\n",
    "plt.barh(x_pos + width/2, sorted_weight, width, label='Weight-Based', alpha=0.8)\n",
    "plt.yticks(x_pos, sorted_features)\n",
    "plt.xlabel('Normalized Importance')\n",
    "plt.title('Feature Importance Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 4: Top 5 most important features\n",
    "plt.subplot(2, 3, 4)\n",
    "top_5 = importance_df.head(5)\n",
    "plt.bar(range(5), top_5['Permutation_Importance'], color='green', alpha=0.7)\n",
    "plt.xticks(range(5), top_5['Feature'], rotation=45, ha='right')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 5 Most Important Features')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 5: Correlation between two methods\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.scatter(importance_df['Permutation_Importance'], \n",
    "           importance_df['Weight_Importance'], \n",
    "           s=100, alpha=0.6, color='purple')\n",
    "\n",
    "for i, feature in enumerate(importance_df['Feature']):\n",
    "    plt.annotate(feature, \n",
    "                (importance_df['Permutation_Importance'].iloc[i], \n",
    "                 importance_df['Weight_Importance'].iloc[i]),\n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.ylabel('Weight-Based Importance')\n",
    "plt.title('Correlation Between Methods')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Feature importance heatmap\n",
    "plt.subplot(2, 3, 6)\n",
    "importance_matrix = importance_df[['Permutation_Importance', 'Weight_Importance']].T.values\n",
    "\n",
    "# Normalize each row\n",
    "importance_matrix_norm = importance_matrix / importance_matrix.max(axis=1, keepdims=True)\n",
    "\n",
    "im = plt.imshow(importance_matrix_norm, cmap='YlOrRd', aspect='auto')\n",
    "plt.colorbar(im, label='Normalized Importance')\n",
    "plt.yticks([0, 1], ['Permutation', 'Weight-Based'])\n",
    "plt.xticks(range(len(feature_names)), importance_df['Feature'], rotation=45, ha='right')\n",
    "plt.title('Feature Importance Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed analysis\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Top 3 features\n",
    "top_3 = importance_df.head(3)\n",
    "print(\"\\nðŸ† Top 3 Most Important Features:\")\n",
    "for idx, row in top_3.iterrows():\n",
    "    print(f\"  {row['Feature']:20s} - Permutation: {row['Permutation_Importance']:.4f}, \"\n",
    "          f\"Weight: {row['Weight_Importance']:.4f}\")\n",
    "\n",
    "# Least important features\n",
    "bottom_3 = importance_df.tail(3)\n",
    "print(\"\\nâš  Least Important Features (consider removing):\")\n",
    "for idx, row in bottom_3.iterrows():\n",
    "    print(f\"  {row['Feature']:20s} - Permutation: {row['Permutation_Importance']:.4f}, \"\n",
    "          f\"Weight: {row['Weight_Importance']:.4f}\")\n",
    "\n",
    "# Calculate feature importance groups\n",
    "high_importance = importance_df[importance_df['Permutation_Importance'] > 0.01]\n",
    "medium_importance = importance_df[(importance_df['Permutation_Importance'] > 0.005) & \n",
    "                                 (importance_df['Permutation_Importance'] <= 0.01)]\n",
    "low_importance = importance_df[importance_df['Permutation_Importance'] <= 0.005]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE GROUPING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"High Importance (>1% accuracy drop): {len(high_importance)} features\")\n",
    "if len(high_importance) > 0:\n",
    "    print(f\"  {', '.join(high_importance['Feature'].values)}\")\n",
    "\n",
    "print(f\"\\nMedium Importance (0.5-1% accuracy drop): {len(medium_importance)} features\")\n",
    "if len(medium_importance) > 0:\n",
    "    print(f\"  {', '.join(medium_importance['Feature'].values)}\")\n",
    "\n",
    "print(f\"\\nLow Importance (<0.5% accuracy drop): {len(low_importance)} features\")\n",
    "if len(low_importance) > 0:\n",
    "    print(f\"  {', '.join(low_importance['Feature'].values)}\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ“ Focus on high-importance features for business decisions\")\n",
    "print(\"âœ“ Consider removing low-importance features to simplify the model\")\n",
    "print(\"âœ“ Collect more data for high-importance features if possible\")\n",
    "if len(low_importance) > 0:\n",
    "    print(f\"âœ“ Potential feature reduction: remove {', '.join(low_importance['Feature'].values)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
